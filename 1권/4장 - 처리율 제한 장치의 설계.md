# 4장 - 처리율 제한 장치의 설계

## 개요
* 클라이언트 또는 서비스가 보내는 처리율을 제어하기 위한 장치
  * 임계치를 넘어서면 호출 중단
* 사례
  * 사용자별 초당 2회 이상 새글 불가
  * IP별 하루 10개 이상 계정 불가
  * 디바이스별 주당 5회 이상 리워드 요청 불가
* 좋은점
  * Dos 공격 방지
  * 비용 절감
  * 서버 과부화 방지

## 1단계 - 문제 이해 및 설계 범위 확정
### 적절한 질문하기
* 용도에 대한 질문 : ex) 클라이언트측 OR 서버측
* 제어 규칙에 대한 질문 : ex) IP 기준, 사용자 기준
* 시스템 규모 : ex) 스타트업, 대규모
* 환경 : ex) 분산환경
* 워크로드 구성 여부 : ex) 독립된 서비스? 애플리케이션 코드?
* 에러 응답 반환 여부 : ex) 사용자에게 에러를 명시할지?

### 요구사항 정리하기
* 처리율을 초과하는 요청은 정확하게 제한
* 가능한 적은메모리
* 분산형 처리율 제한 (여러 서버에서 공유)
* 사용자에게 예외 명시 노출
* 결함 감내성 (fault tolerrance) : 제한장치 장애가 시스템에 전파되지 않도록 구현

## 2단계 - 개략적 설계안 제시 및 동의 구하기

### 처리율 제한 장치를 어디에 둘까?
* 클라이언트에 둔다 : 위변조가 가능하고 모든 클라이언트 통제 어렵다
* 서버측에 둔다 : API 서버에 두거나, 처리율 미들웨어 서버를 둔다 (게이트웨이)

> 최근 spring-cloud-gateway 에서 구현하려는 시도를 본 기억
>   https://spring.io/blog/2021/04/05/api-rate-limiting-with-spring-cloud-gateway
> 애플리케이션에서 구현하는것에 의한 성능 저하 우려
> 모든 Gatweay 요청이 Redis 에 의존되어 성능과 안정성에 대한 우려
> 인프라/네트워크 레이어에서 처리 권장

### 처리율 제한 알고리즘
#### 토큰 버킷 알고리즘 (가장 보편적)

##### 파라미터
* 버킷 크기 : ex)  용량이 4
* 토큰 공급률 : ex) 매초 2개의 토큰 추가
##### 원리
* 사전 설정된 양의 토큰이 주기적으로 채워진다
* 토큰이 꽉차면 추가 토큰은 버려짐
* 처리될 때 마다 하나의 토큰 사용
  * 토큰이 있는 경우
    * 하나를 꺼내고 정상 요청 처리
  * 없는 경우
    * 요청이 버려짐
##### 용량 산정
* 통상적으로 API 엔드포인트 마다 둠
  * 하루에 한번 포스팅 (POST /post)
  * 친구는 150명까지 추가 가능 (POST /friends)
  * 좋아요 버튼은 다섯번 까지 가능 (POST /like)
  * API 엔드포인트 3개 -> 사용자별 3개의 버킷
* 용량
  * IP 주소로 제한 : IP 주소별 버킷
  * 초당 1만개 요청으로 제한 : 모든 요청 하나의 버킷
##### 장단점
* 장점
  * 구현이 쉽다
  * 메모리 사용 효율적
  * 짧은 시간의 트래픽 처리 가능 (남은 토큰만 있으면 가능)
* 단점
  * 인자값 튜닝 어려움

#### 누출 버킷 알고리즘

##### 파라미터
* 버킷 크기 : 큐 사이즈 (처리될 항목이 보관)
* 처리율 : 지정된 시간당 처리될 값

##### 원리
* 요청 도착 -> 큐가 가득찼는지 확인 -> 큐에 요청 추가
* 가득차면 새 요청 버림
* 지정된 시간마다 요청 처리

##### 장단점
* 장점
  * 큐의 크기 제한, 메모리 사용량 효율적
  * 고정된 처리율, 안정적 출력이 필요한 경우 사용
* 단점
  * 단시간에 트래픽이 쌓이면 고정된 처리율로 인해 오래된 요청은 쌓이고 최신 요청은 버려짐
  * 인자값 튜닝 어려움

#### 고정 윈도 카운터

##### 원리
* 타임라인을 고정된 간격(ex: 1초)의 윈도우로 나누기
* 각 윈도우마다 카운터를 붙이기
* 요청이 접수되면 카운터에 1 더하기
* 카운터의 값이 임계치에 도달하면 새 요청 버리기
* 새 윈도우가 열리면 새 요청 받기 가능 상태

##### 윈도우 경계 이슈
* 분당 처리 5 요청 허용 시스템
* 시스템 한도 (5) 의 두배 (10) 요청을 하게될 수 있다
  * 0분 59초에 5 요청
  * 1분 00초에 5 요청
##### 장단점
* 장점
  * 메모리 효율이 좋다
  * 이해하기 쉽다
  * 특정 트래픽 패턴에 적합
* 단점
  * 윈도우 경계에 일시적으로 많은 트래픽이 몰리면, 예상보다 많은 처리 이슈

#### 이동 윈도 로깅 알고리즘

* 들어온 요청의 타임스탬프를 기준으로 앞 1분을 확인한다
  * 00:10, 00:30 의 요청이 있던 상태
  * 00:50 의 요청이면 거부되지만 로그 보존
  * 01:40 의 요청이면 00:40의 요청까지 확인한다
    * 즉 00:10, 00:30 요청은 만료된걸로 간주하여 무시된다
    * 00:50의 요청이 남아 있어, 로그의 크기는 2이다
##### 장단점
* 장점
  * 고정 윈도 카운터의 단점 해결 (허용 한도 넘지 않음)
* 단점
  * 다량의 메모리 사용

#### 이동 윈도 카운터 알고리즘

##### 원리
* 고정윈도 (현재 1분, 직전 1분) 와 이동윈도 (현재 시간부터 -1분) 사용
* 예시 (분당 7개 허용)
  * 현재 1분간의 요청 수 + 직전 1분간의 요청 수 * 이동 윈도와 직전 1분이 겹치는 비율
    * 3 + (5 * 70%) = 6.5개 -> 6 -> 1요청 허용
##### 장단점
* 이전시간대와 평균 처리율에 따라 현재 윈도를 계산 -> 짧은 트래픽 대응 가능
* 메모리 효율 좋음 
* 직전 시간대 요청이 균등하게 분포되어 있다고 가정, 추정치 계산, 다소 느슨, 그러나 심각하지 않음, 실험결과 버려진 요청 0.003% 불과함

## 개략적 아키텍처
* 카운터의 값이 어떤 한도를 넘어서 도착한 요청은 거부
* 카운터는 어디에 보관해야 할까?
  * DB : 디스크 접근 때문에 느려서 안됨
  * 캐시 : 메모리 기반이라 빠르고 만료 정책을 지원함
* 주로 레디스를 많이 사용한다.
  * INCR : 메모리 카운터 1 증가
  * EXPIRE : 카운터 타임아웃 설정
* 원리
  * 미들웨어에게 요청을 보낸다.
  * 미들웨어가 레디스 카운터를 가져와서 한도에 도달했는지 검사한다.
  * 도달하면 요청을 거부한다.
  * 도달하지 않았다면 API 서버로 전달하고 카운터를 증가시킨다.

## 3단계: 상세 설계

### 처리율 제한 장치가 사용하는 HTTP 헤더
클라이언트가 처리율 제한에 얼마나 많은 요청을 보낼 수 있는지 알 수 있는 방법 -> HTTP 응답 헤더
너무 많은 요청을 보내면 -> 420 too many request (w/X-Ratelimit-After)
* X-Ratelimit-Remaining : 한도 내에 남은 처리 가능 요청 수
* X-Ratelimit-Limit : 매 한도마다 클라이언트가 전송 할 수 있는 요청의 수
* X-Ratelimit-After : 한도에 걸리지 않으려면 몇초 뒤에 요청해야 하는지

### 경쟁 조건
두 개 요청을 처리하는 스레드가 각각 병렬로 카운터 값을 읽어 +1을 기록 할 수 있다.
![](4%EC%9E%A5%20-%20%EC%B2%98%EB%A6%AC%EC%9C%A8%20%EC%A0%9C%ED%95%9C%20%EC%9E%A5%EC%B9%98%EC%9D%98%20%EC%84%A4%EA%B3%84/image.png)

* 해결 방법으로 락은 성능을 상당히 떨어트려서 비추
* 정렬 집합을 쓰는 방법
  * 뇌피셜 구현
    * redis 대기열에 Value 는 `Score_RequestID` 값으로 요청시간
    * 스케줄러 구현 : Score 값 (요청시간) 으로 정렬, 처리율 제한 순차 처리
      * 이것도 요청이 몰리면 처리량이 떨어지겠네?
        ![](4%EC%9E%A5%20-%20%EC%B2%98%EB%A6%AC%EC%9C%A8%20%EC%A0%9C%ED%95%9C%20%EC%9E%A5%EC%B9%98%EC%9D%98%20%EC%84%A4%EA%B3%84/image%203.png)<!-- {"width":401} -->
>  참고 : [레디스를 이용한 기프티콘 선착순 이벤트 구현](https://velog.io/@hgs-study/redis-sorted-set#-span-stylecolor-lightcoral-sorted-set%EC%9D%B4%EB%9E%80span)
> [\[우아한테크토크\] 엔드게임 이벤트 긴급 대응기  개발자 어!셈블?](https://youtu.be/uWcn7omddxs)

### 동기화 이슈
* 분산환경에서는 무상태 이므로 클라이언트 1,2 가 어떤 처리율 장치를 호출할지 모른다.
* 제한장치가 1은 클라이언트 2를 모르므로 올바른 처리가 어려울 수 있다.
* 고정세션과 같은 방법으로 해결이 가능하지만 추천하지 않는다.
  ![](4%EC%9E%A5%20-%20%EC%B2%98%EB%A6%AC%EC%9C%A8%20%EC%A0%9C%ED%95%9C%20%EC%9E%A5%EC%B9%98%EC%9D%98%20%EC%84%A4%EA%B3%84/image%202.png)<!-- {"width":565} -->
  중앙 집중형 Redis 를 활용하는것이 좋다.
  ![](4%EC%9E%A5%20-%20%EC%B2%98%EB%A6%AC%EC%9C%A8%20%EC%A0%9C%ED%95%9C%20%EC%9E%A5%EC%B9%98%EC%9D%98%20%EC%84%A4%EA%B3%84/image%205.png)<!-- {"width":559} -->

### 성능 최적화
* 여러 IDC 지원
  * 여러 IDC를 위한 처리율 제한장치는 멀리 있는 IDC 의 지연응답시간을 고려하면 까다롭다.
  * 클라우드 플레어는 트래픽을 가까운 에지 서버로 전달하여 해결한다.
* 동기화 성능
  * 최종 일관성 모델을 사용한다.


## 4단계 - 마무리
### 더 알아두면 좋은 것
* 경성 처리율 제한 : 요청 개수는 임계치를 절대 넘어설 수 없다.
* 연성 처리율 제한 : 일정한 시간동안 넘어설 수 있다.
* 지금까지는 모두 애플리케이션 계층 구현이었다.
  * (네트워크 계층) Iptable 을 활용한 처리율 제한 방법
* 처리율 제한에 걸리지 않기 위한 클라이언트 설계
  * 클라이언트측의 캐싱
  * 짧은 시간동안 너무 많은 메세지 보내지 않기
  * 예외나 에러를 처리하는 클라이언트 코드 도입, 우아한 복구 방법 모색
  * 재시도 로직을 구현할때 충분한 백오프 시간을 두기

#대규모시스템설계기초